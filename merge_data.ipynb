{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_glob = glob.glob('full_results/recall' + '*.csv')\n",
    "recall_glob.sort()\n",
    "\n",
    "beh_glob = glob.glob('full_results/beh' + '*.csv')\n",
    "beh_glob.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, beh = [], []\n",
    "\n",
    "for file in recall_glob:\n",
    "    df = pd.read_csv(file, encoding = 'cp1250')\n",
    "    recall.append(df)\n",
    "\n",
    "for file in beh_glob:\n",
    "    df = pd.read_csv(file, encoding = 'cp1250')\n",
    "    beh.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh = [df[~df['trial_type'].str.endswith('_training')] for df in beh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic = [df[df['trial_type'].str.startswith('semantic_')] for df in beh]\n",
    "perceptual = [df[df['trial_type'].str.startswith('perceptual_')] for df in beh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sem = [df[:int(len(df)/2)] for df in semantic]\n",
    "second_sem = [df[int(len(df)/2):] for df in semantic]\n",
    "\n",
    "first_perc = [df[:int(len(df)/2)] for df in perceptual]\n",
    "second_perc = [df[int(len(df)/2):] for df in perceptual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in first_sem:\n",
    "    df.loc[df[\"answer_rt\"] == -1, 'answer_rt'] = np.nan\n",
    "for df in second_sem:\n",
    "    df.loc[df[\"answer_rt\"] == -1, 'answer_rt'] = np.nan\n",
    "for df in first_perc:\n",
    "    df.loc[df[\"answer_rt\"] == -1, 'answer_rt'] = np.nan\n",
    "for df in second_perc:\n",
    "    df.loc[df[\"answer_rt\"] == -1, 'answer_rt'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fs = [df[\"answer_rt\"].mean() for df in first_sem]\n",
    "mean_ss = [df[\"answer_rt\"].mean() for df in second_sem]\n",
    "\n",
    "mean_fp = [df[\"answer_rt\"].mean() for df in first_perc]\n",
    "mean_sp = [df[\"answer_rt\"].mean() for df in second_perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_fs = [df[\"answer_rt\"].std() for df in first_sem]\n",
    "sd_ss = [df[\"answer_rt\"].std() for df in second_sem]\n",
    "\n",
    "sd_fp = [df[\"answer_rt\"].std() for df in first_perc]\n",
    "sd_sp = [df[\"answer_rt\"].std() for df in second_perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - offline, 1 - online\n",
    "\n",
    "for df, mean, std in zip(first_sem, mean_fs, sd_fs):\n",
    "    df['RTV'] = [abs((mean - rt)/std) for rt in df['answer_rt']]\n",
    "for df, mean, std in zip(second_sem, mean_ss, sd_ss):\n",
    "    df['RTV'] = [abs((mean - rt)/std) for rt in df['answer_rt']]\n",
    "for df, mean, std in zip(first_perc, mean_fp, sd_fp):\n",
    "    df['RTV'] = [abs((mean - rt)/std) for rt in df['answer_rt']]\n",
    "for df, mean, std in zip(second_perc, mean_sp, sd_sp):\n",
    "    df['RTV'] = [abs((mean - rt)/std) for rt in df['answer_rt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_fs = [df[\"RTV\"].median() for df in first_sem]\n",
    "median_ss = [df[\"RTV\"].median() for df in second_sem]\n",
    "\n",
    "median_fp = [df[\"RTV\"].median() for df in first_perc]\n",
    "median_sp = [df[\"RTV\"].median() for df in second_perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - offline, 1 - online\n",
    "\n",
    "for df, median in zip(first_sem, median_fs):\n",
    "    df['STATE'] = [0 if rtv > median else 1 for rtv in df['RTV']]\n",
    "for df, median in zip(second_sem, median_ss):\n",
    "    df['STATE'] = [0 if rtv > median else 1 for rtv in df['RTV']]\n",
    "for df, median in zip(first_perc, median_fs):\n",
    "    df['STATE'] = [0 if rtv > median else 1 for rtv in df['RTV']]\n",
    "for df, median in zip(second_perc, median_ss):\n",
    "    df['STATE'] = [0 if rtv > median else 1 for rtv in df['RTV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(first_perc):\n",
    "    print(f\"first: {first_perc[i]['STATE'].value_counts()}\")\n",
    "    print(f\"sec: {second_perc[i]['STATE'].value_counts()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_perc = []\n",
    "for first, second in zip(first_perc, second_perc):\n",
    "    df_merg = pd.concat([first, second])\n",
    "    merged_perc.append(df_merg)\n",
    "\n",
    "merged_sem = []\n",
    "for first, second in zip(first_sem, second_sem):\n",
    "    df_merg = pd.concat([first, second])\n",
    "    merged_sem.append(df_merg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_in_task = []\n",
    "\n",
    "for df in recall:\n",
    "    new = df.loc[df['in_task'] == True]\n",
    "    new.rename(columns = {'acc': 'recall_acc'}, inplace= True)\n",
    "    rec_in_task.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sem_rec, m_perc_rec = [], []\n",
    "\n",
    "for task, recall in zip(merged_sem,rec_in_task):\n",
    "    result = pd.merge(task, recall, on='sentence')\n",
    "    m_sem_rec.append(result)\n",
    "\n",
    "for task, recall in zip(merged_perc,rec_in_task):\n",
    "    result = pd.merge(task, recall, on='sentence')\n",
    "    m_perc_rec.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_cleared, per_cleared = [], []\n",
    "for df in m_sem_rec:\n",
    "    df = df.drop(columns = ['trial_number', 'in_task'])\n",
    "    sem_cleared.append(df)\n",
    "\n",
    "for df in m_perc_rec:\n",
    "    df = df.drop(columns = ['trial_number', 'in_task'])\n",
    "    per_cleared.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_results = []\n",
    "perc_results = []\n",
    "\n",
    "for x in sem_cleared:\n",
    "    online = x.loc[x['STATE'] == 1]\n",
    "    offline = x.loc[x['STATE'] == 0]\n",
    "    online_trial_count = len(online)\n",
    "    offline_trial_count = len(offline)\n",
    "    all_count = online_trial_count + offline_trial_count\n",
    "    online_cor, offline_cor = len(online[online['recall_acc'] == 1]), len(offline[offline['recall_acc'] == 1])\n",
    "    all_acc = online_cor + offline_cor\n",
    "    sem_results.append([online_cor/online_trial_count, offline_cor/offline_trial_count, all_acc/all_count])\n",
    "\n",
    "for x in per_cleared:\n",
    "    online = x.loc[x['STATE'] == 1]\n",
    "    offline = x.loc[x['STATE'] == 0]\n",
    "    online_trial_count = len(online)\n",
    "    offline_trial_count = len(offline)\n",
    "    all_count = online_trial_count + offline_trial_count\n",
    "    online_cor, offline_cor = len(online[online['recall_acc'] == 1]), len(offline[offline['recall_acc'] == 1])\n",
    "    all_acc = online_cor + offline_cor\n",
    "    perc_results.append([online_cor/online_trial_count, offline_cor/offline_trial_count, all_acc/all_count])\n",
    "\n",
    "final_results = []\n",
    "for x, y in zip(sem_results, perc_results):\n",
    "    listn = [x[2],y[2],x[0],x[1],y[0],y[1]]\n",
    "    final_results.append(listn)\n",
    "\n",
    "final_results_df = pd.DataFrame(final_results, columns = ['semantic', 'perceptual', 'semantic_online', 'semantic_offline', 'perceptual_online', 'perceptual_offline'])\n",
    "\n",
    "final_results_df[\"delta_SEM\"] = final_results_df['semantic_online'] - final_results_df['semantic_offline']\n",
    "final_results_df[\"delta_PERC\"] = final_results_df['perceptual_online'] - final_results_df['perceptual_offline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.to_csv('final_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "\n",
    "# Using pandas plot method\n",
    "final_results_df.plot(kind='box', subplots=True, layout=(1, len(df.columns)), figsize=(12, 6), sharey=True, title = \"Recall accuracy comparison\", ylim = (0,1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "reaction_times_semantic = pd.concat([df['answer_rt'] for df in semantic], ignore_index=True)\n",
    "\n",
    "sns.histplot(reaction_times_semantic, kde=True)\n",
    "plt.xlabel('Reaction Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reaction Times in Semantic')\n",
    "plt.xlim(0.3, 4.2)\n",
    "plt.ylim(0, 210)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_times_perceptual = pd.concat([df['answer_rt'] for df in perceptual], ignore_index=True)\n",
    "\n",
    "sns.histplot(reaction_times_perceptual, kde=True)\n",
    "plt.xlabel('Reaction Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reaction Times in Perceptual')\n",
    "plt.xlim(0.3, 4.2)\n",
    "plt.ylim(0, 210)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_mean_reaction_time = reaction_times_semantic.mean()\n",
    "semantic_std_reaction_time = reaction_times_semantic.std()\n",
    "semantic_min_reaction_time = reaction_times_semantic.min()\n",
    "semantic_max_reaction_time = reaction_times_semantic.max()\n",
    "\n",
    "perceptual_mean_reaction_time = reaction_times_perceptual.mean()\n",
    "perceptual_std_reaction_time = reaction_times_perceptual.std()\n",
    "perceptual_min_reaction_time = reaction_times_perceptual.min()\n",
    "perceptual_max_reaction_time = reaction_times_perceptual.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"semantic_mean_reaction_time: {semantic_mean_reaction_time}\\nsemantic_std_reaction_time: {semantic_std_reaction_time}\\nsemantic_min_reaction_time: {semantic_min_reaction_time}\\nsemantic_max_reaction_time: {semantic_max_reaction_time}\\n\\nperceptual_mean_reaction_time: {perceptual_mean_reaction_time}\\nperceptual_std_reaction_time: {perceptual_std_reaction_time}\\nperceptual_min_reaction_time: {perceptual_min_reaction_time}\\nperceptual_max_reaction_time: {3.666825}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = merged_sem + merged_perc\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "reaction_times_state_0 = combined_df[combined_df['STATE'] == 0]['answer_rt']\n",
    "reaction_times_state_1 = combined_df[combined_df['STATE'] == 1]['answer_rt']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(reaction_times_state_0, kde=True, color='blue', label='Offline')\n",
    "sns.histplot(reaction_times_state_1, kde=True, color='orange', label='Online')\n",
    "\n",
    "plt.xlabel('Reaction Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reaction Times by Offline/Online State')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_all = m_sem_rec + m_perc_rec\n",
    "\n",
    "recall_dict = {}\n",
    "\n",
    "for dataframe in m_all:\n",
    "    for _, row in dataframe.iterrows():\n",
    "\n",
    "        sentence = row['sentence']\n",
    "        recall_acc = row['recall_acc']\n",
    "        if sentence not in recall_dict:\n",
    "            recall_dict[sentence] = {'num_recall': 0, 'num_occurrence': 0}\n",
    "        \n",
    "        recall_dict[sentence]['num_recall'] += recall_acc\n",
    "        recall_dict[sentence]['num_occurrence'] += 1\n",
    "\n",
    "sentence_usage_recall = pd.DataFrame([(sentence, values['num_recall'], values['num_occurrence']) \n",
    "                          for sentence, values in recall_dict.items()], \n",
    "                         columns=['sentence', 'num_recall', 'num_occurrence'])\n",
    "\n",
    "sentence_usage_recall['recall_percentage'] = sentence_usage_recall['num_recall'] / sentence_usage_recall['num_occurrence'] * 100\n",
    "\n",
    "sentence_usage_recall = sentence_usage_recall.sort_values('recall_percentage', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=sentence_usage_recall, x='recall_percentage', y='sentence', palette='viridis')\n",
    "plt.xlabel('Recall Percentage')\n",
    "plt.ylabel('Sentence')\n",
    "plt.yticks([])\n",
    "plt.title('Recall Percentage by Sentence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_usage_recall = sentence_usage_recall.sort_values('num_occurrence', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=sentence_usage_recall, x='num_occurrence', y='sentence', palette='viridis')\n",
    "plt.xlabel('Number of sentences in experimental trials')\n",
    "plt.ylabel('Sentence')\n",
    "plt.yticks([])\n",
    "plt.title('Occurence of each sentence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_dict = {}\n",
    "\n",
    "for dataframe in m_sem_rec:\n",
    "    for _, row in dataframe.iterrows():\n",
    "\n",
    "        sentence = row['sentence']\n",
    "        recall_acc = row['recall_acc']\n",
    "        if sentence not in recall_dict:\n",
    "            recall_dict[sentence] = {'num_recall': 0, 'num_occurrence': 0}\n",
    "        \n",
    "        recall_dict[sentence]['num_recall'] += recall_acc\n",
    "        recall_dict[sentence]['num_occurrence'] += 1\n",
    "\n",
    "sentence_usage_recall_sem = pd.DataFrame([(sentence, values['num_recall'], values['num_occurrence']) \n",
    "                          for sentence, values in recall_dict.items()], \n",
    "                         columns=['sentence', 'num_recall', 'num_occurrence'])\n",
    "\n",
    "sentence_usage_recall_sem['recall_percentage'] = sentence_usage_recall_sem['num_recall'] / sentence_usage_recall_sem['num_occurrence'] * 100\n",
    "\n",
    "sentence_usage_recall_sem = sentence_usage_recall_sem.sort_values('sentence', ascending = True)\n",
    "sentence_usage_recall_sem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_dict = {}\n",
    "\n",
    "for dataframe in m_perc_rec:\n",
    "    for _, row in dataframe.iterrows():\n",
    "\n",
    "        sentence = row['sentence']\n",
    "        recall_acc = row['recall_acc']\n",
    "        if sentence not in recall_dict:\n",
    "            recall_dict[sentence] = {'num_recall': 0, 'num_occurrence': 0}\n",
    "        \n",
    "        recall_dict[sentence]['num_recall'] += recall_acc\n",
    "        recall_dict[sentence]['num_occurrence'] += 1\n",
    "\n",
    "sentence_usage_recall_perc = pd.DataFrame([(sentence, values['num_recall'], values['num_occurrence']) \n",
    "                          for sentence, values in recall_dict.items()], \n",
    "                         columns=['sentence', 'num_recall', 'num_occurrence'])\n",
    "\n",
    "sentence_usage_recall_perc['recall_percentage'] = sentence_usage_recall_perc['num_recall'] / sentence_usage_recall_perc['num_occurrence'] * 100\n",
    "\n",
    "sentence_usage_recall_perc = sentence_usage_recall_perc.sort_values('sentence', ascending = True)\n",
    "sentence_usage_recall_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_usage_recall_sem = sentence_usage_recall_sem.rename(columns={'num_recall': 'num_recall_sem', \n",
    "                                         'num_occurrence': 'num_occurrence_sem', \n",
    "                                         'recall_percentage': 'recall_percentage_sem'})\n",
    "sentence_usage_recall_perc = sentence_usage_recall_perc.rename(columns={'num_recall': 'num_recall_perc', \n",
    "                                           'num_occurrence': 'num_occurrence_perc', \n",
    "                                           'recall_percentage': 'recall_percentage_perc'})\n",
    "\n",
    "sentence_usage_recall_compar = pd.concat([sentence_usage_recall_sem.set_index('sentence'), sentence_usage_recall_perc.set_index('sentence')], axis=1)\n",
    "\n",
    "sentence_usage_recall_compar.reset_index(inplace=True)\n",
    "\n",
    "sentence_usage_recall_compar[340:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
